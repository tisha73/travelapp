{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Never flying with them again! The horrible was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>Such a smooth experience! The perfect was air ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>A huge disappointment. The uncomfortable was f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>A truly enjoyable flight! The amazing was seat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Fairly standard. The average was baggage handl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            Reviews\n",
       "0  negative  Never flying with them again! The horrible was...\n",
       "1  positive  Such a smooth experience! The perfect was air ...\n",
       "2  negative  A huge disappointment. The uncomfortable was f...\n",
       "3  positive  A truly enjoyable flight! The amazing was seat...\n",
       "4   neutral  Fairly standard. The average was baggage handl..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"Datas//flights_merged_by_Hiral.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8371 entries, 0 to 8370\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  8371 non-null   object\n",
      " 1   Reviews    8371 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 130.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"Datas//flights_merged_by_Hiral.csv\", usecols=[\"Reviews\", \"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentiment length after cleaning: 8\n",
      "Problematic rows:\n",
      "Empty DataFrame\n",
      "Columns: [sentiment, Reviews]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check if any sentiment values exceed the allowed length\n",
    "max_length = df[\"sentiment\"].apply(len).max()\n",
    "print(f\"Max sentiment length after cleaning: {max_length}\")\n",
    "\n",
    "# Print rows where sentiment is longer than 20 characters\n",
    "problematic_rows = df[df[\"sentiment\"].apply(len) > 20]\n",
    "print(\"Problematic rows:\")\n",
    "print(problematic_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df[\"sentiment\"] = df[\"sentiment\"].apply(lambda x: re.sub(r\"\\s+\", \" \", x).strip())  # Remove extra spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host: None, User: None\n",
      "Max sentiment length after cleaning: 8\n",
      "Problematic rows: \n",
      "Empty DataFrame\n",
      "Columns: [sentiment, Reviews]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cursor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     conn = mysql.connector.connect(**\u001b[43mDB_CONFIG\u001b[49m)\n\u001b[32m     31\u001b[39m     cursor = conn.cursor()\n",
      "\u001b[31mNameError\u001b[39m: name 'DB_CONFIG' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcursor\u001b[49m:\n\u001b[32m     58\u001b[39m         cursor.close()\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m conn:\n",
      "\u001b[31mNameError\u001b[39m: name 'cursor' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection details\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "DB_URL = os.getenv(\"DB_URL\")\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "\n",
    "# Read CSV file\n",
    "csv_file_path = r\"Datas//flights_merged_by_Hiral.csv\"\n",
    "df = pd.read_csv(csv_file_path, usecols=[\"Reviews\", \"sentiment\"])\n",
    "\n",
    "# Ensure sentiment values are strings, strip extra spaces, and within the correct length\n",
    "df[\"sentiment\"] = df[\"sentiment\"].astype(str).str.strip()  # Remove leading/trailing spaces\n",
    "df[\"sentiment\"] = df[\"sentiment\"].str[:20]  # Trim to 20 characters max\n",
    "\n",
    "# Check if any sentiment values exceed 20 characters\n",
    "print(f\"Max sentiment length after cleaning: {df['sentiment'].astype(str).apply(len).max()}\")\n",
    "\n",
    "# Verify if any problematic rows exist\n",
    "problematic_rows = df[df[\"sentiment\"].apply(len) > 20]\n",
    "print(f\"Problematic rows: \\n{problematic_rows}\")\n",
    "# Establish database connection\n",
    "try:\n",
    "    conn = mysql.connector.connect(**DB_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Database connection established.\")\n",
    "\n",
    "    print(\"First few rows before inserting:\")\n",
    "    print(df[:5])  # Show first 5 rows\n",
    "\n",
    "    # SQL query to insert data\n",
    "    sql = \"INSERT INTO review (reviews, sentiment) VALUES (%s, %s)\"\n",
    "\n",
    "    # Define batch size\n",
    "    batch_size = 100  \n",
    "    data = list(df.itertuples(index=False, name=None))\n",
    "\n",
    "    # Insert data in batches\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data[i : i + batch_size]\n",
    "        cursor.executemany(sql, batch)  \n",
    "        conn.commit()\n",
    "        print(f\"Inserted {i + len(batch)} records...\")  \n",
    "\n",
    "    print(\"All records inserted successfully.\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error: {err}\")\n",
    "\n",
    "finally:\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if conn:\n",
    "        conn.close()\n",
    "    print(\"Database connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mysql.connector\n",
    "# import pandas as pd\n",
    "\n",
    "# # Load the CSV file into a DataFrame\n",
    "# df = pd.read_csv(r\"C:\\Users\\RUTVIK\\flight_pipeline\\Merged_df.csv\")\n",
    "\n",
    "\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# ### Insert Data into review Table ###\n",
    "# insert_review_query = \"\"\"\n",
    "# INSERT INTO review (reviews, sentiment) VALUES (%s, %s)\n",
    "# \"\"\"\n",
    "\n",
    "# batch_size = 500  # Insert 500 rows at a time\n",
    "# batch = []\n",
    "\n",
    "# for i, row in df.iterrows():\n",
    "#     batch.append((row[\"Reviews\"], row[\"sentiment\"]))\n",
    "    \n",
    "#     if len(batch) >= batch_size:\n",
    "#         cursor.executemany(insert_review_query, batch)\n",
    "#         conn.commit()  # Commit every 500 records\n",
    "#         batch = []  # Reset batch\n",
    "\n",
    "# # Insert any remaining records\n",
    "# if batch:\n",
    "#     cursor.executemany(insert_review_query, batch)\n",
    "#     conn.commit()\n",
    "\n",
    "# # import mysql.connector\n",
    "# # import pandas as pd\n",
    "# # import os\n",
    "\n",
    "# # # Load the CSV file into a DataFrame\n",
    "# # df = pd.read_csv(r\"C:\\Users\\RUTVIK\\flight_pipeline\\Merged_df.csv\")\n",
    "\n",
    "# # # Establish MySQL database connection\n",
    "# # host = os.getenv(\"DB_HOST\")\n",
    "# # user = os.getenv(\"DB_USER\")\n",
    "# # password = os.getenv(\"DB_PASSWORD\")\n",
    "# # database = os.getenv(\"flight\")\n",
    "\n",
    "# # # Print to check if values are loaded correctly\n",
    "# # print(f\"Host: {host}, User: {user}\")\n",
    "\n",
    "# # try:\n",
    "# #     cursor = conn.cursor()\n",
    "\n",
    "# #     # Insert Data into review Table\n",
    "# #     insert_review_query = \"\"\"\n",
    "# #     INSERT INTO review (reviews, sentiment) VALUES (%s, %s)\n",
    "# #     \"\"\"\n",
    "\n",
    "# #     batch_size = 500  # Insert 500 rows at a time\n",
    "# #     batch = []\n",
    "\n",
    "# #     for i, row in df.iterrows():\n",
    "# #         batch.append((row[\"Reviews\"], row[\"sentiment\"]))\n",
    "        \n",
    "# #         if len(batch) >= batch_size:\n",
    "# #             cursor.executemany(insert_review_query, batch)\n",
    "# #             conn.commit()  # Commit every 500 records\n",
    "# #             batch = []  # Reset batch\n",
    "\n",
    "# #     # Insert any remaining records\n",
    "# #     if batch:\n",
    "# #         cursor.executemany(insert_review_query, batch)\n",
    "# #         conn.commit()\n",
    "        \n",
    "# #     print(\"Reviews successfully imported into the review table!\")\n",
    "    \n",
    "# # finally:\n",
    "# #     # Close the cursor and connection\n",
    "# #     cursor.close()\n",
    "# #     conn.close()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host: localhost, User: root\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUTVIK\\AppData\\Local\\Temp\\ipykernel_19964\\2679510178.py:24: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved successfully!\n",
      "                                             reviews sentiment\n",
      "0  Never flying with them again! The horrible was...  positive\n",
      "1  Never flying with them again! The horrible was...  negative\n",
      "2  Such a smooth experience! The perfect was air ...  positive\n",
      "3  A huge disappointment. The uncomfortable was f...  negative\n",
      "4  A truly enjoyable flight! The amazing was seat...  positive\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "# Fetch database credentials\n",
    "host = os.getenv(\"DB_HOST\")\n",
    "user = os.getenv(\"DB_USER\")\n",
    "password = os.getenv(\"DB_PASSWORD\")\n",
    "database = os.getenv(\"flight\")\n",
    "\n",
    "# Print to check if values are loaded correctly\n",
    "print(f\"Host: {host}, User: {user}\")\n",
    "\n",
    "# Function to fetch data from MySQL\n",
    "def fetch_data_from_db(table_name):\n",
    "    try:\n",
    "        # Establish connection\n",
    "        conn = mysql.connector.connect(**DB_CONFIG)\n",
    "        \n",
    "        # Query to select all data from the given table\n",
    "        query = f\"SELECT * FROM {table_name}\"\n",
    "        \n",
    "        # Load data into Pandas DataFrame\n",
    "        df = pd.read_sql(query, conn)\n",
    "        \n",
    "        # Close connection\n",
    "        conn.close()\n",
    "        \n",
    "        print(\"Data retrieved successfully!\")\n",
    "        return df\n",
    "\n",
    "    except mysql.connector.Error as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Specify the table name\n",
    "table_name = \"review\"\n",
    "\n",
    "# Retrieve data and store in DataFrame\n",
    "df = fetch_data_from_db(table_name)\n",
    "\n",
    "# Display first few rows\n",
    "if df is not None:\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting joblib\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/301.8 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 41.0/301.8 kB 393.8 kB/s eta 0:00:01\n",
      "   --------- ----------------------------- 71.7/301.8 kB 491.5 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 143.4/301.8 kB 774.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  297.0/301.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 301.8/301.8 kB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: joblib\n",
      "Successfully installed joblib-1.4.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy\n",
      "  Downloading SQLAlchemy-2.0.38-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy)\n",
      "  Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\rutvik\\flight_pipeline\\flight\\lib\\site-packages (from sqlalchemy) (4.12.2)\n",
      "Downloading SQLAlchemy-2.0.38-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.1 MB 435.7 kB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.1/2.1 MB 544.7 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.2/2.1 MB 1.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.4/2.1 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/2.1 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.1 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.2/2.1 MB 3.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.5/2.1 MB 3.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.1 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "   ---------------------------------------- 0.0/299.7 kB ? eta -:--:--\n",
      "   ---------------------------------------  297.0/299.7 kB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 299.7/299.7 kB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: greenlet, sqlalchemy\n",
      "Successfully installed greenlet-3.1.1 sqlalchemy-2.0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\rutvik\\flight_pipeline\\flight\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ------------------- ------------------ 30.7/60.8 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.8/60.8 kB 647.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rutvik\\flight_pipeline\\flight\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/11.1 MB 3.6 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.3/11.1 MB 3.8 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.7/11.1 MB 4.6 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.9/11.1 MB 4.7 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.1/11.1 MB 5.0 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.5/11.1 MB 5.3 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.9/11.1 MB 5.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.2/11.1 MB 5.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.4/11.1 MB 5.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.8/11.1 MB 6.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.2/11.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.3/11.1 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.7/11.1 MB 6.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.9/11.1 MB 6.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.1/11.1 MB 5.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.1/11.1 MB 5.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.3/11.1 MB 5.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.4/11.1 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.6/11.1 MB 5.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.7/11.1 MB 5.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.9/11.1 MB 4.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.0/11.1 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.1/11.1 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.2/11.1 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.3/11.1 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.4/11.1 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.5/11.1 MB 4.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.6/11.1 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.8/11.1 MB 4.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.9/11.1 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.0/11.1 MB 4.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.2/11.1 MB 4.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.3/11.1 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.4/11.1 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.5/11.1 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.7/11.1 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.8/11.1 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.0/11.1 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.1/11.1 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.2/11.1 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.1 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.5/11.1 MB 3.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.6/11.1 MB 3.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.8/11.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.9/11.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.1/11.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.2/11.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.4/11.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.5/11.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.8/11.1 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.0/11.1 MB 3.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.2/11.1 MB 3.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.3/11.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.5/11.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.7/11.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.9/11.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.1/11.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.3/11.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.5/11.1 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.1/11.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.1/11.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl (40.9 MB)\n",
      "   ---------------------------------------- 0.0/40.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/40.9 MB 4.6 MB/s eta 0:00:09\n",
      "   ---------------------------------------- 0.4/40.9 MB 4.1 MB/s eta 0:00:10\n",
      "    --------------------------------------- 0.6/40.9 MB 4.4 MB/s eta 0:00:10\n",
      "    --------------------------------------- 0.8/40.9 MB 4.4 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 1.0/40.9 MB 4.6 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.3/40.9 MB 4.5 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.5/40.9 MB 4.5 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.7/40.9 MB 4.5 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.9/40.9 MB 4.7 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 2.1/40.9 MB 4.7 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 2.4/40.9 MB 4.7 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 2.6/40.9 MB 4.7 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 2.8/40.9 MB 4.6 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 3.1/40.9 MB 4.8 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 3.1/40.9 MB 4.7 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 3.2/40.9 MB 4.4 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 3.4/40.9 MB 4.3 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 3.6/40.9 MB 4.3 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 3.9/40.9 MB 4.4 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 4.1/40.9 MB 4.4 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 4.3/40.9 MB 4.5 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 4.5/40.9 MB 4.5 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 4.8/40.9 MB 4.5 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 5.0/40.9 MB 4.5 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 5.1/40.9 MB 4.4 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 5.2/40.9 MB 4.3 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 5.3/40.9 MB 4.2 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 5.4/40.9 MB 4.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 5.4/40.9 MB 4.0 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 5.5/40.9 MB 4.0 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 5.6/40.9 MB 3.9 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.6/40.9 MB 3.8 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.7/40.9 MB 3.7 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.7/40.9 MB 3.7 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.8/40.9 MB 3.6 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.8/40.9 MB 3.5 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 5.9/40.9 MB 3.4 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 5.9/40.9 MB 3.4 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 6.0/40.9 MB 3.3 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 6.1/40.9 MB 3.3 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 6.1/40.9 MB 3.2 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 6.2/40.9 MB 3.2 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 6.3/40.9 MB 3.2 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 6.3/40.9 MB 3.1 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 6.4/40.9 MB 3.1 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 6.5/40.9 MB 3.0 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 6.6/40.9 MB 3.0 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 6.7/40.9 MB 3.0 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 6.8/40.9 MB 3.0 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 6.9/40.9 MB 3.0 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 7.0/40.9 MB 2.9 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 7.0/40.9 MB 2.9 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 7.1/40.9 MB 2.9 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 7.2/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 7.2/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 7.4/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 7.5/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 7.6/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 7.7/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 7.8/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 8.0/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 8.1/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 8.2/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 8.3/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 8.4/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 8.6/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 8.7/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 8.8/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 9.0/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 9.1/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 9.3/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 9.4/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 9.6/40.9 MB 2.8 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 9.7/40.9 MB 2.8 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 9.9/40.9 MB 2.8 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 10.1/40.9 MB 2.9 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 10.2/40.9 MB 2.9 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 10.4/40.9 MB 2.9 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 10.5/40.9 MB 2.8 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 10.7/40.9 MB 2.8 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 10.9/40.9 MB 2.8 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 11.0/40.9 MB 2.8 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 11.2/40.9 MB 2.8 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 11.4/40.9 MB 2.8 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 11.6/40.9 MB 2.8 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 11.8/40.9 MB 2.8 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 12.0/40.9 MB 2.8 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 12.1/40.9 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 12.3/40.9 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 12.5/40.9 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 12.7/40.9 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 12.9/40.9 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 13.1/40.9 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 13.3/40.9 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 13.5/40.9 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 13.6/40.9 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 13.9/40.9 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 14.1/40.9 MB 2.8 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 14.4/40.9 MB 2.8 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 14.6/40.9 MB 2.8 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 14.8/40.9 MB 2.8 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 15.0/40.9 MB 2.8 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 15.2/40.9 MB 2.8 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 15.5/40.9 MB 2.8 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 15.7/40.9 MB 2.9 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 15.9/40.9 MB 3.0 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 16.2/40.9 MB 3.2 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 16.4/40.9 MB 3.3 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 16.6/40.9 MB 3.4 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 16.9/40.9 MB 3.5 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 17.0/40.9 MB 3.6 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 17.3/40.9 MB 3.7 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 17.5/40.9 MB 3.8 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 17.7/40.9 MB 3.9 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 17.8/40.9 MB 3.9 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 18.0/40.9 MB 3.9 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 18.1/40.9 MB 4.0 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 18.3/40.9 MB 3.9 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 18.3/40.9 MB 3.9 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 18.4/40.9 MB 3.9 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 18.5/40.9 MB 3.8 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 18.5/40.9 MB 3.8 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 18.6/40.9 MB 3.8 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 18.6/40.9 MB 3.8 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 18.6/40.9 MB 3.7 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 18.7/40.9 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 18.7/40.9 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 18.8/40.9 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 18.9/40.9 MB 3.5 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 19.0/40.9 MB 3.5 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 19.0/40.9 MB 3.5 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 19.1/40.9 MB 3.5 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 19.2/40.9 MB 3.4 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 19.3/40.9 MB 3.4 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 19.4/40.9 MB 3.4 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 19.5/40.9 MB 3.4 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 19.5/40.9 MB 3.4 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 19.6/40.9 MB 3.3 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 19.7/40.9 MB 3.3 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 19.8/40.9 MB 3.3 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 19.9/40.9 MB 3.3 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 20.0/40.9 MB 3.3 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 20.2/40.9 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 20.3/40.9 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 20.4/40.9 MB 3.2 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 20.5/40.9 MB 3.2 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 20.6/40.9 MB 3.2 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 20.8/40.9 MB 3.2 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 20.9/40.9 MB 3.2 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 21.0/40.9 MB 3.2 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 21.1/40.9 MB 3.2 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 21.3/40.9 MB 3.1 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 21.4/40.9 MB 3.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 21.6/40.9 MB 3.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 21.7/40.9 MB 3.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 21.8/40.9 MB 3.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 22.0/40.9 MB 3.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 22.1/40.9 MB 3.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 22.2/40.9 MB 3.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 22.4/40.9 MB 3.1 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 22.5/40.9 MB 3.1 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 22.7/40.9 MB 3.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 22.8/40.9 MB 3.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 23.0/40.9 MB 3.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 23.2/40.9 MB 3.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 23.3/40.9 MB 3.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 23.5/40.9 MB 3.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 23.7/40.9 MB 3.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 23.8/40.9 MB 3.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 24.0/40.9 MB 3.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 24.2/40.9 MB 3.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 24.4/40.9 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 24.6/40.9 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 24.8/40.9 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 25.0/40.9 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 25.2/40.9 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 25.4/40.9 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 25.6/40.9 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 25.8/40.9 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 26.0/40.9 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 26.2/40.9 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 26.4/40.9 MB 2.9 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 26.6/40.9 MB 2.9 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 26.8/40.9 MB 2.9 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 27.0/40.9 MB 2.9 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 27.2/40.9 MB 2.9 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 27.4/40.9 MB 2.9 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 27.6/40.9 MB 2.9 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 27.9/40.9 MB 2.9 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 28.1/40.9 MB 2.9 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 28.3/40.9 MB 2.9 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 28.6/40.9 MB 3.0 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 28.8/40.9 MB 3.1 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 29.0/40.9 MB 3.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 29.3/40.9 MB 3.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 29.5/40.9 MB 3.5 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 29.7/40.9 MB 3.6 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 30.0/40.9 MB 3.7 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 30.2/40.9 MB 3.8 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 30.3/40.9 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 30.6/40.9 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 30.8/40.9 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 30.9/40.9 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 30.9/40.9 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 31.0/40.9 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 31.1/40.9 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 31.2/40.9 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 31.3/40.9 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 31.3/40.9 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 31.4/40.9 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 31.5/40.9 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 31.5/40.9 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 31.6/40.9 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 31.7/40.9 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 31.8/40.9 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 31.8/40.9 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 31.9/40.9 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 32.0/40.9 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 32.1/40.9 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 32.2/40.9 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 32.3/40.9 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 32.4/40.9 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 32.5/40.9 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 32.6/40.9 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 32.7/40.9 MB 3.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 32.8/40.9 MB 3.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 32.9/40.9 MB 3.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 33.0/40.9 MB 3.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 33.1/40.9 MB 3.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 33.2/40.9 MB 3.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 33.3/40.9 MB 3.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 33.4/40.9 MB 3.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 33.5/40.9 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 33.5/40.9 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 33.6/40.9 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 33.8/40.9 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 33.9/40.9 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 34.0/40.9 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 34.2/40.9 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 34.3/40.9 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 34.4/40.9 MB 3.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 34.6/40.9 MB 3.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 34.7/40.9 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 34.8/40.9 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 35.0/40.9 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 35.1/40.9 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 35.3/40.9 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 35.4/40.9 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 35.6/40.9 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 35.8/40.9 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 35.9/40.9 MB 3.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 36.1/40.9 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 36.3/40.9 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 36.4/40.9 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 36.6/40.9 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 36.8/40.9 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 37.0/40.9 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 37.2/40.9 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 37.3/40.9 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 37.5/40.9 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 37.7/40.9 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 37.9/40.9 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 38.0/40.9 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.2/40.9 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.4/40.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.6/40.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.8/40.9 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.0/40.9 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.2/40.9 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.4/40.9 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.6/40.9 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.8/40.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.0/40.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.2/40.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.5/40.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.7/40.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/40.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/40.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/40.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/40.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/40.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 40.9/40.9 MB 2.8 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-2.1.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\rutvik\\flight_pipeline\\flight\\lib\\site-packages (from xgboost) (2.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\rutvik\\flight_pipeline\\flight\\lib\\site-packages (from xgboost) (1.15.2)\n",
      "Using cached xgboost-2.1.4-py3-none-win_amd64.whl (124.9 MB)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 10.2/45.0 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 20.5/45.0 kB 131.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.0/45.0 kB 318.6 kB/s eta 0:00:00\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB_URL loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve DB URL from environment variables\n",
    "DB_URL = os.getenv(\"DB_URL\")\n",
    "\n",
    "# Check if the value is loaded\n",
    "if DB_URL:\n",
    "    print(\"DB_URL loaded successfully!\")\n",
    "else:\n",
    "    print(\"Failed to load DB_URL. Check your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RUTVIK\\flight_pipeline\\flight\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m367/367\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.7729 - loss: 0.7041 - val_accuracy: 1.0000 - val_loss: 0.0088\n",
      "Epoch 2/10\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 9.8884e-04 - val_accuracy: 1.0000 - val_loss: 4.0296e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.7895e-04 - val_accuracy: 1.0000 - val_loss: 2.0822e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 3.0668e-04 - val_accuracy: 1.0000 - val_loss: 1.2431e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.4989e-04 - val_accuracy: 1.0000 - val_loss: 8.2188e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 8.9634e-05 - val_accuracy: 1.0000 - val_loss: 6.8680e-05\n",
      "Epoch 8/10\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.2308e-04 - val_accuracy: 1.0000 - val_loss: 4.5474e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.4163e-04 - val_accuracy: 1.0000 - val_loss: 3.2867e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 3.4959e-04 - val_accuracy: 1.0000 - val_loss: 2.4814e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 1.0000\n",
      "XGBoost Accuracy: 1.0000\n",
      "Deep Learning Model Accuracy: 1.0000\n",
      "Best Model: Random Forest\n",
      "                                                  reviews sentiment  \\\n",
      "0       Never flying with them again! The horrible was...  positive   \n",
      "1       Never flying with them again! The horrible was...  negative   \n",
      "2       Such a smooth experience! The perfect was air ...  positive   \n",
      "3       A huge disappointment. The uncomfortable was f...  negative   \n",
      "4       A truly enjoyable flight! The amazing was seat...  positive   \n",
      "...                                                   ...       ...   \n",
      "117190  Never flying with them again! The frustrating ...  negative   \n",
      "117191  Not the best, not the worstjust fair. The WiF...   neutral   \n",
      "117192  Pretty average overall. The reasonable was bag...   neutral   \n",
      "117193  I had an amazing flight. The amazing was bagga...  positive   \n",
      "117194  I can't believe how horrible this flight was. ...  negative   \n",
      "\n",
      "       Predicted_Sentiment  \n",
      "0                 Negative  \n",
      "1                 Negative  \n",
      "2                 Positive  \n",
      "3                 Negative  \n",
      "4                 Positive  \n",
      "...                    ...  \n",
      "117190            Negative  \n",
      "117191             Neutral  \n",
      "117192             Neutral  \n",
      "117193            Positive  \n",
      "117194            Negative  \n",
      "\n",
      "[117195 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import pickle\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "DB_URL = os.getenv(\"DB_URL\")\n",
    "\n",
    "# Establish database connection\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "# Load flight reviews from database\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql('SELECT * FROM review', conn)\n",
    "\n",
    "# Text Cleaning Class\n",
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.apply(self.clean_text)\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_text(text):\n",
    "        text = str(text).lower()\n",
    "        text = re.sub(r'\\W', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "\n",
    "# Apply text cleaning\n",
    "cleaner = TextCleaner()\n",
    "df['cleaned_review'] = cleaner.transform(df['reviews'])\n",
    "\n",
    "# Encode sentiment labels\n",
    "sentiment_mapping = {\"positive\": 1, \"negative\": 0, \"neutral\": 2}\n",
    "df[\"sentiment\"] = df[\"sentiment\"].map(sentiment_mapping)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"cleaned_review\"], df[\"sentiment\"], test_size=0.2, random_state=42, stratify=df[\"sentiment\"]\n",
    ")\n",
    "\n",
    "# TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=50000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Save vectorizer\n",
    "pickle.dump(vectorizer, open(\"tfidf_vectorizer.pkl\", \"wb\"))\n",
    "\n",
    "# Train Random Forest Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=30, random_state=42)\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "joblib.dump(rf_model, \"random_forest.pkl\")\n",
    "\n",
    "# Train XGBoost Model\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=300, learning_rate=0.1, max_depth=6, eval_metric=\"mlogloss\")\n",
    "xgb_model.fit(X_train_tfidf, y_train)\n",
    "joblib.dump(xgb_model, \"xgboost.pkl\")\n",
    "\n",
    "# Train Deep Learning Model\n",
    "tokenizer = Tokenizer(num_words=50000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=100, padding=\"post\")\n",
    "X_test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=100, padding=\"post\")\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=50000, output_dim=32, input_length=100),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(3, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train_seq, y_train, epochs=10, batch_size=256, validation_data=(X_test_seq, y_test))\n",
    "model.save(\"tf_sentiment_model.h5\")\n",
    "pickle.dump(tokenizer, open(\"tokenizer.pkl\", \"wb\"))\n",
    "\n",
    "# Evaluate Random Forest Model\n",
    "rf_accuracy = accuracy_score(y_test, rf_model.predict(X_test_tfidf))\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "\n",
    "# Evaluate XGBoost Model\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_model.predict(X_test_tfidf))\n",
    "print(f\"XGBoost Accuracy: {xgb_accuracy:.4f}\")\n",
    "\n",
    "# Evaluate Deep Learning Model\n",
    "dl_accuracy = model.evaluate(X_test_seq, y_test, verbose=0)[1]\n",
    "print(f\"Deep Learning Model Accuracy: {dl_accuracy:.4f}\")\n",
    "\n",
    "# Determine the best model\n",
    "best_model_name = \"Random Forest\" if rf_accuracy >= xgb_accuracy and rf_accuracy >= dl_accuracy else (\n",
    "    \"XGBoost\" if xgb_accuracy >= dl_accuracy else \"Deep Learning\"\n",
    ")\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "\n",
    "# Continue with the further process using the best model\n",
    "best_model = rf_model if best_model_name == \"Random Forest\" else (\n",
    "    xgb_model if best_model_name == \"XGBoost\" else model\n",
    ")\n",
    "\n",
    "# Sentiment Pipeline\n",
    "vectorizer = pickle.load(open(\"tfidf_vectorizer.pkl\", \"rb\"))\n",
    "\n",
    "if best_model_name == \"Deep Learning\":\n",
    "    sentiment_pipeline = Pipeline([\n",
    "        ('text_cleaning', TextCleaner()),\n",
    "        ('tokenizer', Tokenizer(num_words=50000, oov_token=\"<OOV>\")),\n",
    "        ('pad_sequences', None),  # Custom transformer for padding sequences can be created\n",
    "        ('classifier', best_model)\n",
    "    ])\n",
    "else:\n",
    "    sentiment_pipeline = Pipeline([\n",
    "        ('text_cleaning', TextCleaner()),\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('classifier', best_model)\n",
    "    ])\n",
    "\n",
    "joblib.dump(sentiment_pipeline, \"sentiment.pkl\")\n",
    "\n",
    "# Sentiment Prediction Function\n",
    "def predict_sentiment(review_text):\n",
    "    review_df = pd.DataFrame({\"review\": [review_text]})\n",
    "    prediction = sentiment_pipeline.predict(review_df[\"review\"])[0]\n",
    "    sentiment_labels = {1: \"Positive\", 0: \"Negative\", 2: \"Neutral\"}\n",
    "    return sentiment_labels[prediction]\n",
    "\n",
    "# Load flight reviews for inference\n",
    "with engine.connect() as conn:\n",
    "    inference_reviews = pd.read_sql('SELECT * FROM review', conn)\n",
    "\n",
    "inference_reviews[\"Predicted_Sentiment\"] = inference_reviews[\"reviews\"].apply(lambda x: predict_sentiment(x))\n",
    "\n",
    "print(inference_reviews)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host: localhost, User: root\n"
     ]
    }
   ],
   "source": [
    "host = os.getenv(\"DB_HOST\")\n",
    "user = os.getenv(\"DB_USER\")\n",
    "password = os.getenv(\"DB_PASSWORD\")\n",
    "database = os.getenv(\"flight\")\n",
    "\n",
    "# Print to check if values are loaded correctly\n",
    "print(f\"Host: {host}, User: {user}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection established.\n",
      "Inserted 100 records...\n",
      "Inserted 200 records...\n",
      "Inserted 300 records...\n",
      "Inserted 400 records...\n",
      "Inserted 500 records...\n",
      "Inserted 600 records...\n",
      "Inserted 700 records...\n",
      "Inserted 800 records...\n",
      "Inserted 900 records...\n",
      "Inserted 1000 records...\n",
      "Inserted 1100 records...\n",
      "Inserted 1200 records...\n",
      "Inserted 1300 records...\n",
      "Inserted 1400 records...\n",
      "Inserted 1500 records...\n",
      "Inserted 1600 records...\n",
      "Inserted 1700 records...\n",
      "Inserted 1800 records...\n",
      "Inserted 1900 records...\n",
      "Inserted 2000 records...\n",
      "Inserted 2100 records...\n",
      "Inserted 2200 records...\n",
      "Inserted 2300 records...\n",
      "Inserted 2400 records...\n",
      "Inserted 2500 records...\n",
      "Inserted 2600 records...\n",
      "Inserted 2700 records...\n",
      "Inserted 2800 records...\n",
      "Inserted 2900 records...\n",
      "Inserted 3000 records...\n",
      "Inserted 3100 records...\n",
      "Inserted 3200 records...\n",
      "Inserted 3300 records...\n",
      "Inserted 3400 records...\n",
      "Inserted 3500 records...\n",
      "Inserted 3600 records...\n",
      "Inserted 3700 records...\n",
      "Inserted 3800 records...\n",
      "Inserted 3900 records...\n",
      "Inserted 4000 records...\n",
      "Inserted 4100 records...\n",
      "Inserted 4200 records...\n",
      "Inserted 4300 records...\n",
      "Inserted 4400 records...\n",
      "Inserted 4500 records...\n",
      "Inserted 4600 records...\n",
      "Inserted 4700 records...\n",
      "Inserted 4800 records...\n",
      "Inserted 4900 records...\n",
      "Inserted 5000 records...\n",
      "Inserted 5100 records...\n",
      "Inserted 5200 records...\n",
      "Inserted 5300 records...\n",
      "Inserted 5400 records...\n",
      "Inserted 5500 records...\n",
      "Inserted 5600 records...\n",
      "Inserted 5700 records...\n",
      "Inserted 5800 records...\n",
      "Inserted 5900 records...\n",
      "Inserted 6000 records...\n",
      "Inserted 6100 records...\n",
      "Inserted 6200 records...\n",
      "Inserted 6300 records...\n",
      "Inserted 6400 records...\n",
      "Inserted 6500 records...\n",
      "Inserted 6600 records...\n",
      "Inserted 6700 records...\n",
      "Inserted 6800 records...\n",
      "Inserted 6900 records...\n",
      "Inserted 7000 records...\n",
      "Inserted 7100 records...\n",
      "Inserted 7200 records...\n",
      "Inserted 7300 records...\n",
      "Inserted 7400 records...\n",
      "Inserted 7500 records...\n",
      "Inserted 7600 records...\n",
      "Inserted 7700 records...\n",
      "Inserted 7800 records...\n",
      "Inserted 7900 records...\n",
      "Inserted 8000 records...\n",
      "Inserted 8100 records...\n",
      "Inserted 8200 records...\n",
      "Inserted 8300 records...\n",
      "Inserted 8371 records...\n",
      "All records inserted successfully.\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "# Read CSV file\n",
    "csv_file_path = r\"C:\\Users\\RUTVIK\\flight_pipeline\\Merged_df.csv\"\n",
    "df = pd.read_csv(csv_file_path, usecols=[\"Reviews\"])\n",
    "\n",
    "try:\n",
    "    conn = mysql.connector.connect(**DB_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Database connection established.\")\n",
    "\n",
    "    # print(\"First few rows before inserting:\")\n",
    "    # print(df[:5])  # Show first 5 rows\n",
    "\n",
    "    # SQL query to insert data\n",
    "    sql = \"INSERT INTO Test_review (Reviews) VALUES (%s)\"\n",
    "\n",
    "    # Define batch size\n",
    "    batch_size = 100  \n",
    "    data = list(df.itertuples(index=False, name=None))\n",
    "\n",
    "    # Insert data in batches\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data[i : i + batch_size]\n",
    "        cursor.executemany(sql, batch)  \n",
    "        conn.commit()\n",
    "        print(f\"Inserted {i + len(batch)} records...\")  \n",
    "\n",
    "    print(\"All records inserted successfully.\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error: {err}\")\n",
    "\n",
    "finally:\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if conn:\n",
    "        conn.close()\n",
    "    print(\"Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                reviews  Predicted_Sentiment\n",
      "0     Never flying with them again! The horrible was...                    0\n",
      "1     Such a smooth experience! The perfect was air ...                    1\n",
      "2     A huge disappointment. The uncomfortable was f...                    0\n",
      "3     A truly enjoyable flight! The amazing was seat...                    1\n",
      "4     Fairly standard. The average was baggage handl...                    2\n",
      "...                                                 ...                  ...\n",
      "8366  Never flying with them again! The frustrating ...                    0\n",
      "8367  Not the best, not the worstjust fair. The WiF...                    2\n",
      "8368  Pretty average overall. The reasonable was bag...                    2\n",
      "8369  I had an amazing flight. The amazing was bagga...                    1\n",
      "8370  I can't believe how horrible this flight was. ...                    0\n",
      "\n",
      "[8371 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "# from CarReviews_model_pipeline import TextCleaner\n",
    "\n",
    "# Load the trained model\n",
    "sentiment = joblib.load(\"sentiment.pkl\")\n",
    "# print(sentiment)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "DB_URL = os.getenv(\"DB_URL\")\n",
    "\n",
    "# Establish database connection\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    inference_Review_car = pd.read_sql('SELECT * FROM Test_review', conn)\n",
    "\n",
    "\n",
    "def predict_sentiment(review_text):\n",
    "    review_df = pd.DataFrame({\"review\": [review_text]})  # Convert to DataFrame\n",
    "    prediction = sentiment.predict(review_df[\"review\"])[0]  # Predict\n",
    "    # sentiment_labels = {1: \"Positive\", 0: \"Negative\", 2: \"Neutral\"}\n",
    "    return prediction\n",
    "\n",
    "inference_Review_car[\"Predicted_Sentiment\"] = inference_Review_car[\"reviews\"].apply(lambda x: predict_sentiment(x))\n",
    "\n",
    "print(inference_Review_car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
